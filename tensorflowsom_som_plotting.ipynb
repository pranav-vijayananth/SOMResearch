{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflowsom_som_plotting.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pduXTRl-30xepBS1N0tzorUqiPzKhp1a",
      "authorship_tag": "ABX9TyNOmfVBMAkxdf+otCkFOdwV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranav-vijayananth/SOMResearch/blob/main/tensorflowsom_som_plotting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUjaW22wCdc1"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/cgorman/tensorflow-som/master/tf_som.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--I8noTTDw_D"
      },
      "source": [
        "!pip3 install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YVLSWKeDyRg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tf_som import SelfOrganizingMap\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial import distance_matrix\n",
        "import subprocess\n",
        "from collections import Counter\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "import logging\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBynmSJ-D01q"
      },
      "source": [
        "def get_umatrix(input_vects, weights, m, n):\n",
        "    umatrix = np.zeros((m * n, 1))\n",
        "    neuron_locs = list()\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            neuron_locs.append(np.array([i, j]))\n",
        "    neuron_distmat = distance_matrix(neuron_locs, neuron_locs)\n",
        "\n",
        "    for i in range(m * n):\n",
        "\n",
        "        neighbor_idxs = neuron_distmat[i] <= 1 #CHANGE TO 2 LATER\n",
        "        neighbor_weights = weights[neighbor_idxs]\n",
        "        umatrix[i] = distance_matrix(np.expand_dims(weights[i], 0), neighbor_weights).mean()\n",
        "\n",
        "    bmu_indices = []\n",
        "    for vect in input_vects:\n",
        "        min_index = min([i for i in range(len(list(weights)))],\n",
        "                        key=lambda x: np.linalg.norm(vect-\n",
        "                                                     list(weights)[x]))\n",
        "        bmu_indices.append(neuron_locs[min_index])\n",
        "        \n",
        "    return umatrix, bmu_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buNt-btkFvBB"
      },
      "source": [
        "filename = \"zoo.csv\"\n",
        "datafile = open(f\"/content/drive/MyDrive/Datasets/commonfiles/{filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znKd_a27GgUR"
      },
      "source": [
        "#DATA PREP\n",
        "\n",
        "data = []\n",
        "groundtruth = []\n",
        "dataread = datafile.readline()\n",
        "dataread = datafile.readline()\n",
        "\n",
        "while dataread != \"\": \n",
        "  a = dataread.split(\",\")\n",
        "  l2 = []\n",
        "  for j in range(0, len(a), 1):\n",
        "    if j == len(a)-1:\n",
        "      groundtruth.append(a[j].strip())\n",
        "    else:\n",
        "      try: \n",
        "        l2.append(float(a[j]))\n",
        "      except:\n",
        "        l2.append(0)\n",
        "  data.append(l2)\n",
        "  dataread = datafile.readline()\n",
        "\n",
        "rows = len(data)\n",
        "cols = len(data[0])\n",
        "num_inputs = rows * cols\n",
        "\n",
        "datafile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pimidOe5bdnL"
      },
      "source": [
        "print(f\"This is the data: {data}\")\n",
        "print(f\"Number of cols: {cols}\")\n",
        "print(f\"These are the number of rows {rows}\")\n",
        "print(f\"This is the grountruth: {groundtruth}\")\n",
        "print(f\"Number of input vectors: {num_inputs}\")\n",
        "\n",
        "#CLUSTERS\n",
        "uniqueValues = Counter(groundtruth).keys()\n",
        "clusters = len(uniqueValues)\n",
        "print(f\"The clusters in dataset: {clusters}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKhYdt5FHueb"
      },
      "source": [
        "#CREATING THE TENSORFLOW GRAPH AND LOGS FOR THE MODEL\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "  session = tf.Session(config=tf.ConfigProto(\n",
        "            allow_soft_placement=True,\n",
        "            log_device_placement=False\n",
        "  ))\n",
        "\n",
        "  #NEURONS FOR FEATURE MAP \n",
        "  neurons = int(5*math.sqrt(rows))\n",
        "  m = int(math.sqrt(neurons)+1)\n",
        "  n = int(math.sqrt(neurons)+1)\n",
        "  neurons = (m*n)\n",
        "\n",
        "  #BATCH SIZE \n",
        "  batch_size = 16\n",
        "\n",
        "  #CONVERT TO NUMPY ARRAY FOR TF DATA PIPELINE\n",
        "  data = np.array(data, dtype=\"float32\")\n",
        "\n",
        "  #MAKING THE TENSORFLOW DATRASET PIPELINE \n",
        "  input_data = tf.data.Dataset.from_tensor_slices(data)\n",
        "  input_data = input_data.repeat()\n",
        "  input_data = input_data.batch(batch_size)\n",
        "  iterator = input_data.make_one_shot_iterator()\n",
        "  next_element = iterator.get_next()\n",
        "\n",
        "  #BUILDING THE SOM OBJECT\n",
        "  som = SelfOrganizingMap(m=20, n=20, dim=cols, max_epochs=100, session=session, graph=graph, input_tensor=next_element, batch_size=batch_size, initial_learning_rate=0.1, model_name='Self-Organizing-Map', softmax_activity=True)\n",
        "\n",
        "  #MAKING + RUNNING SESSION\n",
        "  init_op = tf.global_variables_initializer()\n",
        "  session.run([init_op])\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  #TRAINING\n",
        "  som.train(num_inputs)\n",
        "\n",
        "  stop = time.time()\n",
        "\n",
        "  #TIME \n",
        "  print(f\"Training time: {stop - start}s\")\n",
        "\n",
        "  #WEIGHTS\n",
        "  som_weights = som.output_weights\n",
        "\n",
        "  #PLOTTING THE HEAT MAP\n",
        "  umatrix, bmu_loc = get_umatrix(data, som_weights, 20, 20)\n",
        "  fig = plt.figure(10)\n",
        "  plt.imshow(umatrix.reshape((20, 20)), origin='lower')\n",
        "  plt.show(block=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}