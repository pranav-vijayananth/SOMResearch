{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pranav_tensorflow_som.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TwtsdWVevTng6h0PAfxY6ksgnSktd5xw",
      "authorship_tag": "ABX9TyNx/AR8SycFjpFmCLE9Zga2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranav-vijayananth/SOMResearch/blob/main/pranav_tensorflow_som.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7zQ0cjD5bf0"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/cgorman/tensorflow-som/master/tf_som.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQMWv6oU2PWa"
      },
      "source": [
        "!pip3 install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PS883FlwAOb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tf_som import SelfOrganizingMap\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial import distance_matrix\n",
        "import subprocess\n",
        "from collections import Counter\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "import logging\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE4ENBkE921l"
      },
      "source": [
        "def get_labels_from_prediction(prediction):\n",
        "  labels = []\n",
        "  for res in prediction: \n",
        "    for index in range(0, len(res), 1):\n",
        "      if res[index] == 1:\n",
        "        labels.append(index)\n",
        "        break \n",
        "  \n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8TF4SXLqPra"
      },
      "source": [
        "#FUNCTION FOR GETTING HEAT MAP OF CLUSTERS AND THE BMU LOCATIONS\n",
        "def get_umatrix(input_vects, weights, m, n):\n",
        "    umatrix = np.zeros((m * n, 1))\n",
        "    neuron_locs = list()\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            neuron_locs.append(np.array([i, j]))\n",
        "\n",
        "    neuron_distmat = distance_matrix(neuron_locs, neuron_locs)\n",
        "\n",
        "    for i in range(m * n):\n",
        "        neighbor_idxs = neuron_distmat[i] <= 1  \n",
        "        neighbor_weights = weights[neighbor_idxs]\n",
        "        umatrix[i] = distance_matrix(np.expand_dims(weights[i], 0), neighbor_weights).mean()\n",
        "\n",
        "    bmu_indices = []\n",
        "    for vect in input_vects:\n",
        "        min_index = min([i for i in range(len(list(weights)))],\n",
        "                        key=lambda x: np.linalg.norm(vect-\n",
        "                                                     list(weights)[x]))\n",
        "        bmu_indices.append(neuron_locs[min_index])\n",
        "        \n",
        "    return umatrix, bmu_indices\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVq3rTcg9-KU"
      },
      "source": [
        "filename = \"breast-cancer.csv\"\n",
        "datafile = open(\"/content/drive/MyDrive/Datasets/commonfiles/\"+filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2r1OUBI9__n"
      },
      "source": [
        "data = []\n",
        "groundtruth = []\n",
        "dataread = datafile.readline()\n",
        "dataread = datafile.readline()\n",
        "\n",
        "while dataread != \"\": \n",
        "  a = dataread.split(\",\")\n",
        "  l2 = []\n",
        "  for j in range(0, len(a), 1):\n",
        "    if j == len(a)-1:\n",
        "      groundtruth.append(a[j].strip())\n",
        "    else:\n",
        "      try: \n",
        "        l2.append(float(a[j]))\n",
        "      except:\n",
        "        l2.append(0)\n",
        "  data.append(l2)\n",
        "  dataread = datafile.readline()\n",
        "\n",
        "rows = len(data)\n",
        "cols = len(data[0])\n",
        "num_inputs = rows * cols\n",
        "\n",
        "datafile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_F_NGWd-B0M"
      },
      "source": [
        "print(f\"This is the data: {data}\")\n",
        "print(f\"Number of cols: {cols}\")\n",
        "print(f\"These are the number of rows {rows}\")\n",
        "print(f\"This is the grountruth: {groundtruth}\")\n",
        "print(f\"Number of input vectors: {num_inputs}\")\n",
        "\n",
        "#CLUSTERS\n",
        "uniqueValues = Counter(groundtruth).keys()\n",
        "clusters = len(uniqueValues)\n",
        "print(f\"The clusters in dataset: {clusters}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c08RWV5N-Sj7"
      },
      "source": [
        "# bash_command = \"touch /content/drive/MyDrive/Datasets/Research/TensorFlow-SOM/\"+filename+\".txt\"\n",
        "# subprocess.run(bash_command, shell=True)\n",
        "\n",
        "# fw = open(\"/content/drive/MyDrive/Datasets/Research/TensorFlow-SOM/\"+filename+\".txt\", \"a\")\n",
        "\n",
        "#CREATING THE TENSORFLOW GRAPH AND LOGS FOR THE MODEL\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "  session = tf.Session(config=tf.ConfigProto(\n",
        "            allow_soft_placement=True,\n",
        "            log_device_placement=False\n",
        "  ))\n",
        "\n",
        "  #NEURONS FOR FEATURE MAP \n",
        "  # neurons = int((5*math.sqrt(rows)))\n",
        "  # m = int(math.sqrt(neurons))+1\n",
        "  # n = int(math.sqrt(neurons))+1\n",
        "  # neurons = (m*n)\n",
        "\n",
        "  #BATCH SIZE \n",
        "  batch_size = 32\n",
        "\n",
        "  #CONVERT TO NUMPY ARRAY FOR TF DATA PIPELINE\n",
        "  data = np.array(data, dtype=\"float32\")\n",
        "\n",
        "  #MAKING THE TENSORFLOW DATRASET PIPELINE \n",
        "  input_data = tf.data.Dataset.from_tensor_slices(data)\n",
        "  input_data = input_data.repeat()\n",
        "  input_data = input_data.batch(batch_size)\n",
        "  iterator = input_data.make_one_shot_iterator()\n",
        "  next_element = iterator.get_next()\n",
        "\n",
        "  #BUILDING THE SOM OBJECT\n",
        "  som = SelfOrganizingMap(m=clusters, n=clusters, dim=cols, max_epochs=20, session=session, graph=graph, input_tensor=next_element, batch_size=batch_size, initial_learning_rate=0.1, model_name='Self-Organizing-Map', softmax_activity=True)\n",
        "\n",
        "  #MAKING + RUNNING SESSION\n",
        "  init_op = tf.global_variables_initializer()\n",
        "  session.run([init_op])\n",
        "\n",
        "  #TRAINING\n",
        "  som.train(num_inputs)\n",
        "\n",
        "  #WEIGHTS\n",
        "  som_weights = som.output_weights\n",
        "  print(f\"SOM model weights: {som_weights}\")\n",
        "\n",
        "  #SOM UMATRIX + BMU LOCATION/PREDICTION\n",
        "  umatrix, bmu_loc = get_umatrix(data, som_weights, clusters, clusters)\n",
        "  figure = plt.figure()\n",
        "  # plt.imshow(umatrix.reshape((m, n)), origin=\"lower\")\n",
        "  plt.show(block=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtcR1mlZAtvn"
      },
      "source": [
        "# LABELS\n",
        "for i in range(30):\n",
        "  labels = get_labels_from_prediction(prediction=prediction)\n",
        "  print(labels)\n",
        "\n",
        "  converted_list = [str(element) for element in labels]\n",
        "  joined_string = \",\".join(converted_list)\n",
        "  fw.write(joined_string)\n",
        "  fw.write(\"\\n\")\n",
        "  print(i)\n",
        "\n",
        "fw.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY0SL_j4-XAk"
      },
      "source": [
        "fo = open(\"/content/drive/MyDrive/Datasets/Research/TensorFlow-SOM/\"+filename+\".txt\", \"r\")\n",
        "fw = open(\"/content/drive/MyDrive/Datasets/Research/TensorFlow-SOM/breast-tissue_output.csv\", 'a')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7rhORt4-Xj1"
      },
      "source": [
        "# WRITING EACH ARI INTO OUTPUT.CSV FILE\n",
        "count = 1 \n",
        "fw.write(str(filename))\n",
        "for line in fo: \n",
        "  line = line.strip()\n",
        "  line = line.strip(\"\\n\")\n",
        "  curlabel = line.split(\",\")\n",
        "  if count > 1:\n",
        "    ARI = adjusted_rand_score(prevlabel, curlabel)\n",
        "    print(ARI)\n",
        "    fw.write(','+str(ARI))\n",
        "  \n",
        "  prevlabel = curlabel\n",
        "  count = 2\n",
        "\n",
        "fw.write(\"\\n\")\n",
        "fw.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}